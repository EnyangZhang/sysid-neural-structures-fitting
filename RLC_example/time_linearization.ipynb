{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.integrate import odeint\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from symbolic_RLC import fxu_ODE, fxu_ODE_mod, A_nominal, B_nominal\n",
    "from torchid.neuralode import  NeuralODE, RunningAverageMeter\n",
    "from torchid.ssmodels import NeuralStateSpaceModelLin, NeuralStateSpaceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts = 2e-7\n",
    "A_lin = A_nominal * Ts\n",
    "B_lin = B_nominal * Ts\n",
    "\n",
    "A_lin = np.array([[10, 100], [1000, 10000]])\n",
    "ss_model = NeuralStateSpaceModelLin(A_lin, B_lin)\n",
    "    #ss_model = NeuralStateSpaceModel() #NeuralStateSpaceModelLin(A_nominal*Ts, B_nominal*Ts)\n",
    "nn_solution = NeuralODE(ss_model)\n",
    "    #nn_solution.ss_model.load_state_dict(torch.load(os.path.join(\"models\", \"model.pkl\")))\n",
    "\n",
    "# In[Linearization time - 1 a time]\n",
    "nx = 2\n",
    "nu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_arr = np.random.rand(nx).astype(np.float32)\n",
    "x_torch = torch.tensor(x_arr, requires_grad=True)\n",
    "\n",
    "u_batch = np.random.rand(nu).astype(np.float32)\n",
    "u_torch = torch.tensor(u_batch, requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718 µs ± 44.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1000\n",
    "\n",
    "VAR = []\n",
    "for idx_var in range(nx):\n",
    "    var = np.zeros((1,nx)).astype(np.float32)\n",
    "    var[0,idx_var] = 1.0 # differentiate w.r.t the nth variable\n",
    "    VAR.append(torch.tensor(var))\n",
    "\n",
    "F_xu = ss_model(x_torch,u_torch)\n",
    "A = np.empty((nx,nx))\n",
    "B = np.empty((nx,nu))\n",
    "\n",
    "for idx_var in range(nx):\n",
    "    var = VAR[idx_var]\n",
    "    #var = np.zeros((1,nx)).astype(np.float32)\n",
    "    #var[0,idx_var] = 1.0 # differentiate w.r.t the nth variable\n",
    "    F_xu.backward(var, retain_graph=True)\n",
    "    A[idx_var,:] = np.array(x_torch.grad)\n",
    "    B[idx_var,:] = np.array(u_torch.grad)\n",
    "    x_torch.grad.data.zero_()\n",
    "    u_torch.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[Linearization time - batched]\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "x_batch = np.random.rand(batch_size, nx).astype(np.float32)\n",
    "x_torch = torch.tensor(x_batch, requires_grad=True)\n",
    "\n",
    "u_batch = np.random.rand(batch_size, nu).astype(np.float32)\n",
    "u_torch = torch.tensor(u_batch, requires_grad=True)\n",
    "\n",
    "    \n",
    "    \n",
    "VAR = []\n",
    "for idx_var in range(nx):\n",
    "    var = np.zeros((batch_size,nx)).astype(np.float32)\n",
    "    var[:,idx_var] = 1.0 # differentiate w.r.t the nth variable\n",
    "    VAR.append(torch.tensor(var))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "757 µs ± 118 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1000\n",
    "\n",
    "# In[Linearization time - batched]\n",
    "    \n",
    "F_xu = ss_model(x_torch,u_torch)\n",
    "A = np.empty((batch_size,nx,nx))\n",
    "B = np.empty((batch_size,nx,nu))\n",
    "for idx_var in range(nx):\n",
    "    var = VAR[idx_var]\n",
    "    F_xu.backward(var, retain_graph=True)\n",
    "    A[:,idx_var,:] = np.array(x_torch.grad)\n",
    "    B[:,idx_var,:] = np.array(u_torch.grad)\n",
    "    x_torch.grad.data.zero_()\n",
    "    u_torch.grad.data.zero_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
